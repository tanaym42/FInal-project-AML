{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary stuff for Linear Regression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = pd.read_csv('winequality-red.csv', delimiter=\";\")\n",
    "white = pd.read_csv('winequality-white.csv', delimiter=\";\")\n",
    "wine = pd.concat([red, white], ignore_index=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Multiple Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.28289382549149344\n",
      "RMSE: 0.725458107754197\n"
     ]
    }
   ],
   "source": [
    "#### TESTING WITH ALL VARIABLES\n",
    "\n",
    "# Resplit the Train/test\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(wine.drop(\"quality\", axis=1), wine[\"quality\"], test_size = 0.25, random_state = 1)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Fitting the model on training data\n",
    "lin_reg.fit(x_train2, y_train2)\n",
    "\n",
    "# Making predictions\n",
    "y_pred2 = lin_reg.predict(x_test2)\n",
    "\n",
    "# # Making predictions (training set)\n",
    "# y_pred2_train = lin_reg.predict(x_train2)\n",
    "\n",
    "\n",
    "# Calculate the R-squared value (without cross validation)\n",
    "r_squared = r2_score(y_test2, y_pred2)\n",
    "print('R-squared:', r_squared)\n",
    "result_1 = r_squared\n",
    "\n",
    "# # Cross-validation on the training data\n",
    "# cv_scores = cross_val_score(lin_reg, x_train2, y_train2, cv=5)\n",
    "\n",
    "# # Calculate the mean R-squared value across all folds\n",
    "# cv_mean_r_squared = cv_scores.mean()\n",
    "# print('CV Mean R-squared:', cv_mean_r_squared)\n",
    "\n",
    "# Calculate the RMSE across all folds\n",
    "RMSE = (np.sqrt(metrics.mean_squared_error(y_test2, y_pred2)))\n",
    "print(\"RMSE:\", RMSE )\n",
    "result_2 = RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Paul Kenniston\\Downloads\\LinearRegression.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Paul%20Kenniston/Downloads/LinearRegression.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy on training set: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m accuracy_score(y_train2, y_pred2_train))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Paul%20Kenniston/Downloads/LinearRegression.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy on test set: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m accuracy_score(y_test2, y_pred2))\n",
      "File \u001b[1;32mc:\\Users\\Paul Kenniston\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Paul Kenniston\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "# print('Accuracy on training set: %.2f' % accuracy_score(y_train2, y_pred2_train))\n",
    "# print('Accuracy on test set: %.2f' % accuracy_score(y_test2, y_pred2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Multiple Linear Regression (With Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Mean R-squared: 0.2874356675185207\n",
      "CV Mean RMSE: 0.7407030724735125\n"
     ]
    }
   ],
   "source": [
    "#### TESTING WITH ALL VARIABLES\n",
    "\n",
    "# Resplit the Train/test\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(wine.drop(\"quality\", axis=1), wine[\"quality\"], test_size = 0.25, random_state = 1)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Fitting the model on training data\n",
    "lin_reg.fit(x_train2, y_train2)\n",
    "\n",
    "# Making predictions\n",
    "y_pred2 = lin_reg.predict(x_test2)\n",
    "\n",
    "# Cross-validation on the training data\n",
    "cv_scores = cross_val_score(lin_reg, x_train2, y_train2, cv=5, scoring='r2')\n",
    "\n",
    "# Calculate the mean R-squared value across all folds\n",
    "cv_mean_r_squared = cv_scores.mean()\n",
    "print('CV Mean R-squared:', cv_mean_r_squared)\n",
    "result_3 = cv_mean_r_squared\n",
    "\n",
    "# Cross-validation on the training data\n",
    "cv_scores = cross_val_score(lin_reg, x_train2, y_train2, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Calculate the mean R-squared value across all folds\n",
    "cv_mean_r_squared = cv_scores.mean()\n",
    "print('CV Mean RMSE:', abs(cv_mean_r_squared))\n",
    "result_4 = abs(cv_mean_r_squared)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Multiple Linear Regression (Limited Features using 'SelectKBest')(CV Implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features:\n",
      "['fixed acidity' 'volatile acidity' 'citric acid' 'residual sugar'\n",
      " 'chlorides' 'free sulfur dioxide' 'total sulfur dioxide' 'density' 'pH'\n",
      " 'sulphates' 'alcohol']\n",
      "\n",
      "Selected best 5:\n",
      "['volatile acidity' 'citric acid' 'chlorides' 'density' 'alcohol']\n"
     ]
    }
   ],
   "source": [
    "# Identifying the Best Features\n",
    "\n",
    "X = wine[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar','chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density','pH', 'sulphates', 'alcohol']]\n",
    "Y = wine['quality']\n",
    "\n",
    "select = SelectKBest(score_func=f_regression, k=5)\n",
    "\n",
    "z = select.fit_transform(X, Y)\n",
    "\n",
    "filter = select.get_support()\n",
    "features = array(X.columns)\n",
    "\n",
    "print(\"All features:\")\n",
    "print(features)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Selected best 5:\")\n",
    "print(features[filter])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Mean R-squared: 0.26766395806959153\n",
      "CV Mean RMSE: 0.7509750007152824\n"
     ]
    }
   ],
   "source": [
    "#### TESTING WITH LIMITED VARIABLES\n",
    "\n",
    "X = wine[['volatile acidity', 'citric acid', 'chlorides', 'density', 'alcohol']]\n",
    "Y = wine['quality']\n",
    "\n",
    "# Resplit the Train/test\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X, Y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Fitting the model on training data\n",
    "lin_reg.fit(x_train2, y_train2)\n",
    "\n",
    "# Making predictions\n",
    "y_pred2 = lin_reg.predict(x_test2)\n",
    "\n",
    "# Cross-validation on the training data\n",
    "cv_scores = cross_val_score(lin_reg, x_train2, y_train2, cv=5, scoring='r2')\n",
    "\n",
    "# Calculate the mean R-squared value across all folds\n",
    "cv_mean_r_squared = cv_scores.mean()\n",
    "print('CV Mean R-squared:', cv_mean_r_squared)\n",
    "result_5 = cv_mean_r_squared\n",
    "\n",
    "# Cross-validation on the training data\n",
    "cv_scores = cross_val_score(lin_reg, x_train2, y_train2, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Calculate the mean R-squared value across all folds\n",
    "cv_mean_r_squared = cv_scores.mean()\n",
    "print('CV Mean RMSE:', abs(cv_mean_r_squared))\n",
    "result_6 = abs(cv_mean_r_squared)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Multiple Linear Regression (SMOTE Implemented)(Limited Features using 'SelectKBest')(CV Implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Mean R-squared: 0.45591928547874233\n",
      "CV Mean RMSE: 1.4803079134060204\n"
     ]
    }
   ],
   "source": [
    "#### TESTING WITH LIMITED VARIABLES\n",
    "\n",
    "X = wine[['volatile acidity', 'citric acid', 'chlorides', 'density', 'alcohol']]\n",
    "Y = wine['quality']\n",
    "\n",
    "smote = SMOTE(k_neighbors=3, random_state=42)\n",
    "x_smote, y_smote = smote.fit_resample(X, Y)\n",
    "\n",
    "# Resplit the Train/test\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_smote, y_smote, test_size = 0.25, random_state = 1)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Fitting the model on training data\n",
    "lin_reg.fit(x_train2, y_train2)\n",
    "\n",
    "# Making predictions\n",
    "y_pred2 = lin_reg.predict(x_test2)\n",
    "\n",
    "# Cross-validation on the training data\n",
    "cv_scores = cross_val_score(lin_reg, x_train2, y_train2, cv=5, scoring='r2')\n",
    "\n",
    "# Calculate the mean R-squared value across all folds\n",
    "cv_mean_r_squared = cv_scores.mean()\n",
    "print('CV Mean R-squared:', cv_mean_r_squared)\n",
    "result_7 = cv_mean_r_squared\n",
    "\n",
    "# Cross-validation on the training data\n",
    "cv_scores = cross_val_score(lin_reg, x_train2, y_train2, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Calculate the mean R-squared value across all folds\n",
    "cv_mean_r_squared = cv_scores.mean()\n",
    "print('CV Mean RMSE:', abs(cv_mean_r_squared))\n",
    "result_8 = abs(cv_mean_r_squared)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Baseline\n",
      "R-squared: 0.28289382549149344\n",
      "RMSE: 0.725458107754197\n",
      "\n",
      "Test 2: w/Cross Validation\n",
      "R-squared: 0.2874356675185207\n",
      "RMSE: 0.7407030724735125\n",
      "\n",
      "Test 3: w/Cross Validation & Feature Selection\n",
      "R-squared: 0.26766395806959153\n",
      "RMSE: 0.7509750007152824\n",
      "\n",
      "Test 4: w/Cross Validation & Feature Selection & SMOTE\n",
      "R-squared: 0.45591928547874233\n",
      "RMSE: 1.4803079134060204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test 1: Baseline')\n",
    "print('R-squared:', result_1)\n",
    "print('RMSE:', result_2)\n",
    "print('')\n",
    "\n",
    "print('Test 2: w/Cross Validation')\n",
    "print('R-squared:', result_3)\n",
    "print('RMSE:', result_4)\n",
    "print('')\n",
    "\n",
    "print('Test 3: w/Cross Validation & Feature Selection')\n",
    "print('R-squared:', result_5)\n",
    "print('RMSE:', result_6)\n",
    "print('')\n",
    "\n",
    "print('Test 4: w/Cross Validation & Feature Selection & SMOTE')\n",
    "print('R-squared:', result_7)\n",
    "print('RMSE:', result_8)\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
